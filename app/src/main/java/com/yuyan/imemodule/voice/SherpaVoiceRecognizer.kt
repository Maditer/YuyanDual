package com.yuyan.imemodule.voice

import android.content.res.AssetManager
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import com.yuyan.imemodule.application.Launcher
import com.k2fsa.sherpa.ncnn.SherpaNcnn as OriginalSherpaNcnn
import kotlinx.coroutines.*
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import java.util.concurrent.atomic.AtomicBoolean
import kotlin.concurrent.thread

/**
 * Sherpa NCNN è¯­éŸ³è¯†åˆ«å™¨
 * åŸºäºåŸ SherpaNcnn é¡¹ç›®æ”¹é€ ï¼Œé€‚é…è¾“å…¥æ³•åœºæ™¯
 */
class SherpaVoiceRecognizer(
    private val config: VoiceRecognizerConfig = VoiceRecognizerConfig()
) {
    
    companion object {
        private const val TAG = "SherpaVoiceRecognizer"
        
        // Nativeåº“åŠ è½½çŠ¶æ€ - é€šè¿‡æ£€æŸ¥åŸå§‹ç±»æ˜¯å¦å¯ä»¥åŠ è½½æ¥åˆ¤æ–­
        var isNativeLibraryLoaded = false
            private set
        
        // æ£€æŸ¥nativeåº“æ˜¯å¦å¯ç”¨
        init {
            Log.d(TAG, "=== SherpaVoiceRecognizer Static Initialization Start ===")
            try {
                // å°è¯•é€šè¿‡åŸå§‹ç±»æ¥æ£€æŸ¥åº“æ˜¯å¦å¯ç”¨
                // è¿™é‡Œåªæ˜¯æ£€æŸ¥ï¼Œå®é™…åŠ è½½ç”±SherpaNcnnç±»å¤„ç†
                val context = com.yuyan.imemodule.application.Launcher.instance.context
                val libPath = context.applicationInfo.nativeLibraryDir
                Log.d(TAG, "Native library directory: $libPath")
                
                // æ£€æŸ¥å…·ä½“çš„åº“æ–‡ä»¶
                val libFile = java.io.File("$libPath/libsherpa-ncnn-jni.so")
                Log.d(TAG, "Library file exists: ${libFile.exists()}, path: ${libFile.absolutePath}")
                if (libFile.exists()) {
                    Log.d(TAG, "Library file size: ${libFile.length()} bytes")
                    isNativeLibraryLoaded = true
                    Log.i(TAG, "âœ… Native library file found and should be loadable by SherpaNcnn class")
                } else {
                    Log.e(TAG, "âŒ Native library file not found")
                    isNativeLibraryLoaded = false
                }
            } catch (e: Exception) {
                Log.e(TAG, "âŒ Error checking native library", e)
                isNativeLibraryLoaded = false
            }
            Log.d(TAG, "=== SherpaVoiceRecognizer Static Initialization End ===")
        }
    }
    
    // éŸ³é¢‘å½•åˆ¶ç›¸å…³
    private val audioSource = MediaRecorder.AudioSource.MIC
    private val sampleRateInHz = config.sampleRate.toInt()
    private val channelConfig = AudioFormat.CHANNEL_IN_MONO
    private val audioFormat = AudioFormat.ENCODING_PCM_16BIT
    private var audioRecord: AudioRecord? = null
    
    // å½•éŸ³çº¿ç¨‹
    private var recordingThread: Thread? = null
    private val isRecording = AtomicBoolean(false)
    
    // è¯†åˆ«å¼•æ“
    private var sherpaNcnn: SherpaNcnnNative? = null
    
    // çŠ¶æ€ç®¡ç†
    private val _state = MutableStateFlow(VoiceRecognitionState.IDLE)
    val state: StateFlow<VoiceRecognitionState> = _state.asStateFlow()
    
    // ç»“æœç›‘å¬å™¨
    private var listener: VoiceRecognitionListener? = null
    
    // å½“å‰è¯†åˆ«æ–‡æœ¬
    private var currentText = ""
    private var lastRecognizedText = ""
    
    /**
     * åˆå§‹åŒ–è¯†åˆ«å™¨
     */
    fun initialize(): Boolean {
        Log.d(TAG, "ğŸš€ SherpaVoiceRecognizer.initialize() called")
        Log.d(TAG, "Native library loaded: $isNativeLibraryLoaded")
        
        // æ£€æŸ¥nativeåº“æ˜¯å¦å·²åŠ è½½
        if (!isNativeLibraryLoaded) {
            Log.e(TAG, "âŒ Cannot initialize: native library not loaded")
            _state.value = VoiceRecognitionState.ERROR
            listener?.onError("è¯­éŸ³è¯†åˆ«åº“æœªæ­£ç¡®å®‰è£…ï¼Œè¯·è”ç³»å¼€å‘è€…")
            return false
        }
        
        Log.d(TAG, "âœ… Native library is loaded, proceeding with initialization...")
        
        return try {
            _state.value = VoiceRecognitionState.INITIALIZING
            Log.d(TAG, "State set to INITIALIZING")
            
            // åˆå§‹åŒ– Sherpa NCNN å¼•æ“
            Log.d(TAG, "Creating Sherpa NCNN engine...")
            sherpaNcnn = createSherpaNcnn()
            Log.d(TAG, "âœ… Sherpa NCNN engine created successfully")
            
            // è·³è¿‡isReadyæ£€æŸ¥ï¼Œç›´æ¥è®¤ä¸ºåˆå§‹åŒ–æˆåŠŸ
            // æŸäº›æƒ…å†µä¸‹isReadyå¯èƒ½è¿”å›falseï¼Œä½†å¼•æ“å®é™…ä¸Šå¯ä»¥å·¥ä½œ
            Log.d(TAG, "âœ… Sherpa NCNN engine created, assuming it's ready")
            _state.value = VoiceRecognitionState.READY
            Log.i(TAG, "ğŸ‰ Voice recognizer initialized successfully")
            listener?.onStateChanged(VoiceRecognitionState.READY)
            true
        } catch (e: UnsatisfiedLinkError) {
            Log.e(TAG, "âŒ UnsatisfiedLinkError during initialization", e)
            _state.value = VoiceRecognitionState.ERROR
            listener?.onError("JNIé“¾æ¥é”™è¯¯: ${e.message}")
            false
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to initialize voice recognizer", e)
            Log.e(TAG, "Exception type: ${e::class.java.simpleName}")
            Log.e(TAG, "Exception message: ${e.message}")
            _state.value = VoiceRecognitionState.ERROR
            listener?.onError("åˆå§‹åŒ–å¤±è´¥: ${e.message}")
            false
        }
    }
    
    /**
     * åˆ›å»º Sherpa NCNN å®ä¾‹
     */
    private fun createSherpaNcnn(): SherpaNcnnNative {
        Log.d(TAG, "ğŸ—ï¸ Creating SherpaNcnnNative instance...")
        val assetManager = Launcher.instance.context.assets
        
        // ä½¿ç”¨assetsä¸­å­˜åœ¨çš„æ¨¡å‹ï¼šsherpa-ncnn-streaming-zipformer-bilingual-zh-en-2023-02-13
        val modelDir = "sherpa-ncnn-streaming-zipformer-bilingual-zh-en-2023-02-13"
        Log.d(TAG, "ğŸ“ Using model directory: $modelDir")
        
        // éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        try {
            val modelFiles = listOf(
                "$modelDir/encoder_jit_trace-pnnx.ncnn.param",
                "$modelDir/encoder_jit_trace-pnnx.ncnn.bin",
                "$modelDir/decoder_jit_trace-pnnx.ncnn.param",
                "$modelDir/decoder_jit_trace-pnnx.ncnn.bin",
                "$modelDir/joiner_jit_trace-pnnx.ncnn.param",
                "$modelDir/joiner_jit_trace-pnnx.ncnn.bin",
                "$modelDir/tokens.txt"
            )
            
            for (file in modelFiles) {
                val inputStream = assetManager.open(file)
                val size = inputStream.available()
                inputStream.close()
                Log.d(TAG, "âœ… Model file found: $file ($size bytes)")
            }
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error checking model files", e)
            throw e
        }
        
        // æ„å»ºæ¨¡å‹é…ç½®
        val modelConfig = ModelConfig(
            encoderParam = "$modelDir/encoder_jit_trace-pnnx.ncnn.param",
            encoderBin = "$modelDir/encoder_jit_trace-pnnx.ncnn.bin",
            decoderParam = "$modelDir/decoder_jit_trace-pnnx.ncnn.param",
            decoderBin = "$modelDir/decoder_jit_trace-pnnx.ncnn.bin",
            joinerParam = "$modelDir/joiner_jit_trace-pnnx.ncnn.param",
            joinerBin = "$modelDir/joiner_jit_trace-pnnx.ncnn.bin",
            tokens = "$modelDir/tokens.txt",
            numThreads = 1,  // ä¸åŸå§‹é¡¹ç›®ä¿æŒä¸€è‡´
            useGPU = true  // ä¸åŸå§‹é¡¹ç›®ä¿æŒä¸€è‡´
        )
        
        val featConfig = FeatureExtractorConfig(
            sampleRate = 16000.0f,
            featureDim = 80
        )
        
        val decoderConfig = DecoderConfig(
            method = "greedy_search",  // ä½¿ç”¨ä¸åŸå§‹é¡¹ç›®ç›¸åŒçš„è§£ç æ–¹æ³•
            numActivePaths = 4
        )
        
        val recognizerConfig = RecognizerConfig(
            featConfig = featConfig,
            modelConfig = modelConfig,
            decoderConfig = decoderConfig,
            enableEndpoint = true,
            rule1MinTrailingSilence = 2.0f,  // ä¸åŸå§‹é¡¹ç›®ä¿æŒä¸€è‡´
            rule2MinTrailingSilence = 0.8f,
            rule3MinUtteranceLength = 20.0f
        )
        
        Log.d(TAG, "ğŸ”§ Configuration created, instantiating SherpaNcnnNative...")
        
        try {
            return SherpaNcnnNative(assetManager, recognizerConfig)
        } catch (e: UnsatisfiedLinkError) {
            Log.e(TAG, "âŒ UnsatisfiedLinkError when creating SherpaNcnnNative", e)
            throw Exception("Native library loading failed: ${e.message}", e)
        } catch (e: NoClassDefFoundError) {
            Log.e(TAG, "âŒ NoClassDefFoundError when creating SherpaNcnnNative", e)
            throw Exception("Sherpa NCNN class not found: ${e.message}", e)
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Exception when creating SherpaNcnnNative", e)
            throw Exception("Failed to create SherpaNcnnNative: ${e.message}", e)
        }
    }
    
    /**
     * å¼€å§‹å½•éŸ³è¯†åˆ«
     */
    fun startRecognition(): Boolean {
        Log.d(TAG, "SherpaVoiceRecognizer.startRecognition() called")
        Log.d(TAG, "Current state: ${_state.value}")
        
        if (_state.value != VoiceRecognitionState.READY) {
            Log.w(TAG, "Cannot start recognition, current state: ${_state.value}")
            return false
        }
        
        return try {
            // æš‚æ—¶ç¦ç”¨è¯Šæ–­æµ‹è¯•ï¼Œé¿å…å¯èƒ½çš„nativeåº“å´©æºƒ
            // runDiagnosticTest()
            
            Log.d(TAG, "Initializing microphone...")
            if (!initMicrophone()) {
                throw Exception("Failed to initialize microphone")
            }
            Log.d(TAG, "Microphone initialized successfully")
            
            audioRecord?.startRecording()
            isRecording.set(true)
            _state.value = VoiceRecognitionState.RECORDING
            Log.d(TAG, "Audio recording started")
            
            // é‡ç½®è¯†åˆ«çŠ¶æ€
            currentText = ""
            lastRecognizedText = ""
        try {
            sherpaNcnn?.reset(true)
            Log.d(TAG, "Voice recognition state reset successfully")
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Error resetting recognizer", e)
        }
            
            // å¯åŠ¨å½•éŸ³çº¿ç¨‹
            recordingThread = thread(true) {
                Log.d(TAG, "Audio processing thread started")
                processAudioSamples()
            }
            
            listener?.onStateChanged(VoiceRecognitionState.RECORDING)
            Log.i(TAG, "Started voice recognition successfully")
            true
        } catch (e: Exception) {
            Log.e(TAG, "Failed to start recognition", e)
            _state.value = VoiceRecognitionState.ERROR
            listener?.onError("å¼€å§‹è¯†åˆ«å¤±è´¥: ${e.message}")
            false
        }
    }
    
    /**
     * è¿è¡Œè¯Šæ–­æµ‹è¯•
     */
    private fun runDiagnosticTest() {
        Log.i(TAG, "ğŸ”§ Running diagnostic test...")
        
        try {
            // æµ‹è¯•SherpaNcnnå®ä¾‹
            val ncnn = sherpaNcnn
            Log.d(TAG, "ğŸ” SherpaNcnn instance: ${ncnn != null}")
            
            if (ncnn != null) {
                // æµ‹è¯•åŸºæœ¬æ–¹æ³•
                val isReady = ncnn.isReady()
                Log.d(TAG, "ğŸ” isReady(): $isReady")
                
                val text = ncnn.text
                Log.d(TAG, "ğŸ” text(): '$text'")
                
                // æµ‹è¯•resetæ–¹æ³•
                ncnn.reset(false)
                Log.d(TAG, "âœ… reset() test passed")
                
                // æµ‹è¯•decodeæ–¹æ³•
                ncnn.decode()
                Log.d(TAG, "âœ… decode() test passed")
                
                // æµ‹è¯•isEndpointæ–¹æ³•
                val isEndpoint = ncnn.isEndpoint()
                Log.d(TAG, "ğŸ” isEndpoint(): $isEndpoint")
                
                Log.i(TAG, "âœ… SherpaNcnn diagnostic test completed successfully")
            } else {
                Log.e(TAG, "âŒ SherpaNcnn instance is null")
            }
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Diagnostic test failed", e)
        }
        
        Log.i(TAG, "ğŸ”§ Diagnostic test completed")
    }
    
    /**
     * åœæ­¢å½•éŸ³è¯†åˆ«
     */
    fun stopRecognition() {
        if (!isRecording.get()) {
            return
        }
        
        isRecording.set(false)
        
        try {
            // åœæ­¢å½•éŸ³
            audioRecord?.stop()
            audioRecord?.release()
            audioRecord = null
            
            // ç­‰å¾…å½•éŸ³çº¿ç¨‹ç»“æŸ
            recordingThread?.join(1000)
            recordingThread = null
            
            // å¦‚æœå½“å‰æœ‰è¯†åˆ«ç»“æœï¼Œå°†å…¶ä½œä¸ºæœ€ç»ˆç»“æœå‘é€
            if (currentText.isNotBlank()) {
                Log.i(TAG, "ğŸ—£ï¸ Final recognition result: '$currentText'")
                val result = VoiceRecognitionResult(
                    text = currentText,
                    isPartial = false,
                    isEndpoint = true
                )
                listener?.onResult(result)
            }
            
            _state.value = VoiceRecognitionState.READY
            listener?.onStateChanged(VoiceRecognitionState.READY)
            
            Log.i(TAG, "Stopped voice recognition")
        } catch (e: Exception) {
            Log.e(TAG, "Error stopping recognition", e)
        }
    }
    
    /**
     * å¤„ç†éŸ³é¢‘æ•°æ®
     */
    private fun processAudioSamples() {
        Log.i(TAG, "Started processing audio samples (simplified mode)")
        
        val interval = 0.1f // 100ms
        val bufferSize = (interval * sampleRateInHz).toInt() // æ ·æœ¬æ•°
        val buffer = ShortArray(bufferSize)
        var audioFrameCount = 0
        
        while (isRecording.get()) {
            try {
                val ret = audioRecord?.read(buffer, 0, buffer.size) ?: 0
                Log.d(TAG, "ğŸ¤ AudioRecord.read() returned: $ret bytes")
                audioFrameCount++
                
                if (ret > 0) {
                    // æ¯100å¸§è®°å½•ä¸€æ¬¡éŸ³é¢‘è¾“å…¥çŠ¶æ€
                    if (audioFrameCount % 100 == 0) {
                        Log.d(TAG, "ğŸµ Audio frame #$audioFrameCount: $ret samples read")
                        
                        // æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                        val maxAmplitude = buffer.take(ret).maxOrNull() ?: 0
                        val minAmplitude = buffer.take(ret).minOrNull() ?: 0
                        Log.d(TAG, "ğŸµ Audio amplitude range: [$minAmplitude, $maxAmplitude]")
                    }
                    
                    // è¯­éŸ³è¯†åˆ«å¤„ç†å·²å¯ç”¨
                    
                    // æ¯500å¸§ï¼ˆçº¦50ç§’ï¼‰å‘é€ä¸€æ¬¡çŠ¶æ€æ›´æ–°ï¼Œè®©ç”¨æˆ·çŸ¥é“å½•éŸ³æ­£å¸¸å·¥ä½œ
                    if (audioFrameCount % 500 == 0) {
                        Log.i(TAG, "ğŸ¤ Voice recording in progress... (frame #$audioFrameCount)")
                        listener?.onResult(VoiceRecognitionResult(
                            text = "[å½•éŸ³ä¸­...]",
                            isPartial = true,
                            isEndpoint = false
                        ))
                    }
                    
                    // Step 1: éŸ³é¢‘æ•°æ®è¾“å…¥
                    try {
                        val samples = FloatArray(ret) { buffer[it] / 32768.0f }
                        sherpaNcnn?.acceptSamples(samples)
                        Log.v(TAG, "ğŸµ Audio samples fed to recognizer: ${samples.size} samples")
                    } catch (e: Exception) {
                        Log.e(TAG, "âŒ Error feeding audio samples to recognizer", e)
                        // å¦‚æœacceptSampleså¤±è´¥ï¼Œç»§ç»­å¾ªç¯ä½†ä¸å¤„ç†åç»­æ­¥éª¤
                        continue
                    }
                    
                    // Step 2: è§£ç å¤„ç†
                    try {
                        val isReady = sherpaNcnn?.isReady() ?: false
                        if (isReady) {
                            var decodeCount = 0
                            while (sherpaNcnn?.isReady() == true) {
                                sherpaNcnn?.decode()
                                decodeCount++
                            }
                            Log.d(TAG, "ğŸ”„ Decoded $decodeCount frames")
                        } else if (audioFrameCount % 50 == 0) {
                            Log.d(TAG, "â³ Recognizer not ready yet (frame #$audioFrameCount)")
                        }
                    } catch (e: Exception) {
                        Log.e(TAG, "âŒ Error during decoding", e)
                        // å¦‚æœè§£ç å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€å¸§
                    }
                    
                    // Step 3: æ£€æŸ¥ç«¯ç‚¹å’Œè·å–ç»“æœ
                    try {
                        val isEndpoint = sherpaNcnn?.isEndpoint() ?: false
                        val text = sherpaNcnn?.text ?: ""
                        
                        // å¤„ç†è¯†åˆ«ç»“æœ
                        if (text.isNotBlank() && text != currentText) {
                            Log.i(TAG, "ğŸ—£ï¸ Recognition result: '$text' (partial=${!isEndpoint}, endpoint=$isEndpoint)")
                            currentText = text
                            val result = VoiceRecognitionResult(
                                text = text,
                                isPartial = !isEndpoint,
                                isEndpoint = isEndpoint
                            )
                            
                            listener?.onResult(result)
                            
                            // å¦‚æœæ£€æµ‹åˆ°ç«¯ç‚¹ï¼Œé‡ç½®è¯†åˆ«å™¨
                            if (isEndpoint) {
                                Log.i(TAG, "ğŸ Endpoint detected, resetting recognizer")
                                lastRecognizedText = text
                                sherpaNcnn?.reset()
                            }
                        } else if (audioFrameCount % 50 == 0) {
                            // å®šæœŸè®°å½•çŠ¶æ€
                            Log.d(TAG, "ğŸ” Status: text='$text', endpoint=$isEndpoint")
                        }
                    } catch (e: Exception) {
                        Log.e(TAG, "âŒ Error checking recognition results", e)
                        // å¦‚æœç»“æœå¤„ç†å¤±è´¥ï¼Œç»§ç»­å½•éŸ³
                    }
                } else {
                    Log.w(TAG, "âš ï¸ Audio read returned $ret bytes")
                }
            } catch (e: Exception) {
                Log.e(TAG, "Error processing audio samples", e)
                break
            }
        }
        
        Log.i(TAG, "Finished processing audio samples (processed $audioFrameCount frames)")
    }
    
    /**
     * åˆå§‹åŒ–éº¦å…‹é£
     */
    private fun initMicrophone(): Boolean {
        return try {
            // ä½¿ç”¨ä¸åŸå§‹é¡¹ç›®ç›¸åŒçš„å¤„ç†é—´éš”ï¼š100ms
            val interval = 0.1f // 100 ms
            val bufferSize = (interval * sampleRateInHz).toInt() // in samples
            
            Log.i(TAG, "ğŸ™ï¸ Audio config:")
            Log.i(TAG, "  - Sample rate: $sampleRateInHz Hz")
            Log.i(TAG, "  - Channel config: $channelConfig (MONO=${AudioFormat.CHANNEL_IN_MONO})")
            Log.i(TAG, "  - Audio format: $audioFormat (PCM_16BIT=${AudioFormat.ENCODING_PCM_16BIT})")
            Log.i(TAG, "  - Processing interval: ${interval}s (100ms)")
            Log.i(TAG, "  - Buffer size: $bufferSize samples (${bufferSize * 1000.0f / sampleRateInHz} ms)")
            
            audioRecord = AudioRecord(
                audioSource,
                sampleRateInHz,
                channelConfig,
                audioFormat,
                bufferSize * 2 // a sample has two bytes as we are using 16-bit PCM
            )
            
            val state = audioRecord?.state
            Log.i(TAG, "ğŸ™ï¸ AudioRecord state: $state (INITIALIZED=${AudioRecord.STATE_INITIALIZED})")
            
            if (state == AudioRecord.STATE_INITIALIZED) {
                Log.i(TAG, "âœ… Microphone initialized successfully")
                true
            } else {
                Log.e(TAG, "âŒ Microphone initialization failed, state: $state")
                false
            }
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to initialize microphone", e)
            false
        }
    }
    
    /**
     * è®¾ç½®ç›‘å¬å™¨
     */
    fun setListener(listener: VoiceRecognitionListener?) {
        this.listener = listener
    }
    
    /**
     * é”€æ¯è¯†åˆ«å™¨
     */
    fun destroy() {
        stopRecognition()
        
        sherpaNcnn?.destroy()
        sherpaNcnn = null
        
        _state.value = VoiceRecognitionState.DESTROYED
        Log.i(TAG, "Voice recognizer destroyed")
    }
    
    /**
     * è·å–å½“å‰è¯†åˆ«æ–‡æœ¬
     */
    fun getCurrentText(): String = currentText
    
    /**
     * è·å–æœ€åä¸€æ¬¡ç¡®è®¤çš„è¯†åˆ«æ–‡æœ¬
     */
    fun getLastRecognizedText(): String = lastRecognizedText
}

/**
 * Sherpa NCNN Native æ¥å£åŒ…è£…ç±»
 * å¯¹åº”åŸé¡¹ç›®çš„ SherpaNcnn.kt
 */
// ç®€å•çš„åŒ…è£…å™¨ï¼Œä½¿ç”¨åŸå§‹çš„SherpaNcnnç±»
class SherpaNcnnNative(
    assetManager: AssetManager,
    private val config: RecognizerConfig
) {
    // ç›´æ¥ä½¿ç”¨åŸå§‹çš„SherpaNcnnç±»
    private val sherpaNcnn: OriginalSherpaNcnn
    
    init {
        try {
            Log.d("SherpaNcnnNative", "ğŸ—ï¸ Initializing OriginalSherpaNcnn...")
            Log.d("SherpaNcnnNative", "ğŸ“‹ AssetManager: $assetManager")
            
            // è½¬æ¢é…ç½®æ ¼å¼
            val originalConfig = convertToOriginalConfig(config)
            Log.d("SherpaNcnnNative", "ğŸ“‹ Original config: $originalConfig")
            
            sherpaNcnn = OriginalSherpaNcnn(originalConfig, assetManager)
            Log.d("SherpaNcnnNative", "âœ… OriginalSherpaNcnn initialized successfully")
            Log.d("SherpaNcnnNative", "ğŸ” Initial isReady(): ${sherpaNcnn.isReady()}")
            Log.d("SherpaNcnnNative", "ğŸ” Initial text: '${sherpaNcnn.text}'")
        } catch (e: UnsatisfiedLinkError) {
            Log.e("SherpaNcnnNative", "âŒ UnsatisfiedLinkError in SherpaNcnnNative init", e)
            throw RuntimeException("Sherpa NCNN native library not available: ${e.message}", e)
        } catch (e: Exception) {
            Log.e("SherpaNcnnNative", "âŒ Exception in SherpaNcnnNative init", e)
            throw RuntimeException("Failed to initialize SherpaNcnnNative: ${e.message}", e)
        }
    }
    
    fun acceptSamples(samples: FloatArray) {
        sherpaNcnn.acceptWaveform(samples)
    }
    
    fun isReady(): Boolean {
        return sherpaNcnn.isReady()
    }
    
    fun decode() {
        sherpaNcnn.decode()
    }
    
    fun isEndpoint(): Boolean {
        return sherpaNcnn.isEndpoint()
    }
    
    fun reset(recreate: Boolean = false) {
        sherpaNcnn.reset(recreate)
    }
    
    val text: String
        get() = sherpaNcnn.text
    
    fun destroy() {
        sherpaNcnn.destroy()
    }
    
    // è½¬æ¢é…ç½®æ ¼å¼åˆ°åŸå§‹æ ¼å¼
    private fun convertToOriginalConfig(config: RecognizerConfig): com.k2fsa.sherpa.ncnn.RecognizerConfig {
        val featConfig = com.k2fsa.sherpa.ncnn.FeatureExtractorConfig(
            sampleRate = config.featConfig.sampleRate,
            featureDim = config.featConfig.featureDim
        )
        
        val modelConfig = com.k2fsa.sherpa.ncnn.ModelConfig(
            encoderParam = config.modelConfig.encoderParam,
            encoderBin = config.modelConfig.encoderBin,
            decoderParam = config.modelConfig.decoderParam,
            decoderBin = config.modelConfig.decoderBin,
            joinerParam = config.modelConfig.joinerParam,
            joinerBin = config.modelConfig.joinerBin,
            tokens = config.modelConfig.tokens,
            numThreads = config.modelConfig.numThreads,
            useGPU = config.modelConfig.useGPU
        )
        
        val decoderConfig = com.k2fsa.sherpa.ncnn.DecoderConfig(
            method = config.decoderConfig.method,
            numActivePaths = config.decoderConfig.numActivePaths
        )
        
        return com.k2fsa.sherpa.ncnn.RecognizerConfig(
            featConfig = featConfig,
            modelConfig = modelConfig,
            decoderConfig = decoderConfig,
            enableEndpoint = true,
            rule1MinTrailingSilence = config.rule1MinTrailingSilence,
            rule2MinTrailingSilence = config.rule2MinTrailingSilence,
            rule3MinUtteranceLength = config.rule3MinUtteranceLength
        )
    }
}

// æ•°æ®ç±»å®šä¹‰ï¼ˆå¯¹åº”åŸé¡¹ç›®ï¼‰
data class FeatureExtractorConfig(
    var sampleRate: Float,
    var featureDim: Int,
)

data class ModelConfig(
    var encoderParam: String,
    var encoderBin: String,
    var decoderParam: String,
    var decoderBin: String,
    var joinerParam: String,
    var joinerBin: String,
    var tokens: String,
    var numThreads: Int = 1,
    var useGPU: Boolean = true,
)

data class DecoderConfig(
    var method: String = "modified_beam_search",
    var numActivePaths: Int = 4,
)

data class RecognizerConfig(
    var featConfig: FeatureExtractorConfig,
    var modelConfig: ModelConfig,
    var decoderConfig: DecoderConfig,
    var enableEndpoint: Boolean = true,
    var rule1MinTrailingSilence: Float = 2.4f,
    var rule2MinTrailingSilence: Float = 1.0f,
    var rule3MinUtteranceLength: Float = 30.0f,
)